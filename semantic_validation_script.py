#!/usr/bin/env python3
"""
Semantic validation script to analyze response relevance to prompts
"""
import asyncio
import json
import httpx
from typing import Dict, Any, List, Tuple
from datetime import datetime

# Test cases with expected semantic elements
SEMANTIC_TEST_CASES = [
    {
        "id": 1,
        "query": "–ü–æ–∫–∞–∂–∏ –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ",
        "expected_elements": {
            "entity": "applicants",
            "operation": "count", 
            "filters": [],
            "semantic_focus": "total_count",
            "title_keywords": ["total", "applicants", "candidates", "–æ–±—â–µ–µ", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"]
        }
    },
    {
        "id": 2,
        "query": "–°–∫–æ–ª—å–∫–æ —É –Ω–∞—Å –ø—Ä–∏–Ω—è—Ç—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–æ—Ñ—Ñ–µ—Ä –ø—Ä–∏–Ω—è—Ç)?",
        "expected_elements": {
            "entity": "applicants",
            "operation": "count",
            "filters": ["status_name", "–û—Ñ—Ñ–µ—Ä –ø—Ä–∏–Ω—è—Ç"],
            "semantic_focus": "hired_candidates",
            "title_keywords": ["hired", "accepted", "–ø—Ä–∏–Ω—è—Ç—ã—Ö", "–æ—Ñ—Ñ–µ—Ä"]
        }
    },
    {
        "id": 3,
        "query": "–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ–∫—Ä—É—Ç–µ—Ä–æ–≤ - –∫—Ç–æ –±–æ–ª—å—à–µ –≤—Å–µ—Ö –Ω–∞–Ω—è–ª?",
        "expected_elements": {
            "entity": "applicants",
            "operation": "count",
            "filters": ["status_name", "–û—Ñ—Ñ–µ—Ä –ø—Ä–∏–Ω—è—Ç"],
            "group_by": "recruiter_name",
            "semantic_focus": "recruiter_performance",
            "title_keywords": ["recruiter", "performance", "—Ä–µ–∫—Ä—É—Ç–µ—Ä", "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", "–Ω–∞–Ω—è–ª"]
        }
    },
    {
        "id": 4,
        "query": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º",
        "expected_elements": {
            "entity": "applicants",
            "operation": "count",
            "group_by": "status_name",
            "semantic_focus": "status_distribution", 
            "title_keywords": ["status", "distribution", "—Å—Ç–∞—Ç—É—Å", "—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"]
        }
    },
    {
        "id": 5,
        "query": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ - –æ—Ç–∫—É–¥–∞ –ø—Ä–∏—Ö–æ–¥—è—Ç –ª—É—á—à–∏–µ?",
        "expected_elements": {
            "entity": "applicants",
            "operation": "count",
            "group_by": "source_name",
            "semantic_focus": "source_effectiveness",
            "title_keywords": ["source", "effectiveness", "–∏—Å—Ç–æ—á–Ω–∏–∫", "—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"]
        }
    },
    {
        "id": 6,
        "query": "–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –≤—Å–µ–º –≤–∞–∫–∞–Ω—Å–∏—è–º",
        "expected_elements": {
            "entity": "vacancies",
            "operation": "avg",
            "field": "money",
            "semantic_focus": "average_salary",
            "title_keywords": ["average", "salary", "—Å—Ä–µ–¥–Ω—è—è", "–∑–∞—Ä–ø–ª–∞—Ç–∞"]
        }
    },
    {
        "id": 7,
        "query": "–¢–æ–ø —Ä–µ–∫—Ä—É—Ç–µ—Ä–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤",
        "expected_elements": {
            "entity": "applicants",
            "operation": "count",
            "group_by": "recruiter_name",
            "semantic_focus": "top_recruiters",
            "title_keywords": ["top", "recruiters", "—Ç–æ–ø", "—Ä–µ–∫—Ä—É—Ç–µ—Ä"]
        }
    },
    {
        "id": 8,
        "query": "–ê–∫—Ç–∏–≤–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏",
        "expected_elements": {
            "entity": "vacancies", 
            "operation": "count",
            "filters": ["state", "active"],
            "semantic_focus": "active_vacancies",
            "title_keywords": ["active", "vacancies", "–∞–∫—Ç–∏–≤–Ω—ã–µ", "–≤–∞–∫–∞–Ω—Å–∏–∏"]
        }
    }
]

def analyze_semantic_relevance(query: str, response_json: Dict[str, Any], expected: Dict[str, Any]) -> Dict[str, Any]:
    """Analyze how well the response matches the semantic intent of the query"""
    
    analysis = {
        "query": query,
        "semantic_score": 0,
        "matches": [],
        "mismatches": [],
        "warnings": [],
        "detailed_analysis": {}
    }
    
    # Extract actual response elements
    main_metric = response_json.get("main_metric", {})
    main_value = main_metric.get("value", {})
    chart = response_json.get("chart", {})
    title = response_json.get("report_title", "")
    
    # 1. Entity Relevance (20 points)
    expected_entity = expected["entity"]
    actual_entity = main_value.get("entity")
    
    if actual_entity == expected_entity:
        analysis["semantic_score"] += 20
        analysis["matches"].append(f"‚úÖ Correct entity: {actual_entity}")
    else:
        analysis["mismatches"].append(f"‚ùå Entity mismatch: expected {expected_entity}, got {actual_entity}")
    
    # 2. Operation Relevance (20 points)
    expected_operation = expected["operation"]
    actual_operation = main_value.get("operation")
    
    if actual_operation == expected_operation:
        analysis["semantic_score"] += 20
        analysis["matches"].append(f"‚úÖ Correct operation: {actual_operation}")
    else:
        analysis["mismatches"].append(f"‚ùå Operation mismatch: expected {expected_operation}, got {actual_operation}")
    
    # 3. Filter Relevance (15 points)
    expected_filters = expected.get("filters", [])
    actual_filter = main_value.get("filter", {})
    
    if not expected_filters and not actual_filter:
        analysis["semantic_score"] += 15
        analysis["matches"].append("‚úÖ No filters needed and none applied")
    elif expected_filters:
        if actual_filter:
            filter_field = actual_filter.get("field")
            filter_value = actual_filter.get("value")
            
            if len(expected_filters) >= 2:
                expected_field = expected_filters[0]
                expected_value = expected_filters[1]
                
                if filter_field == expected_field:
                    analysis["semantic_score"] += 10
                    analysis["matches"].append(f"‚úÖ Correct filter field: {filter_field}")
                    
                    if expected_value in str(filter_value):
                        analysis["semantic_score"] += 5
                        analysis["matches"].append(f"‚úÖ Correct filter value: {filter_value}")
                    else:
                        analysis["warnings"].append(f"‚ö†Ô∏è Filter value mismatch: expected {expected_value}, got {filter_value}")
                else:
                    analysis["mismatches"].append(f"‚ùå Filter field mismatch: expected {expected_field}, got {filter_field}")
        else:
            analysis["mismatches"].append(f"‚ùå Missing expected filter: {expected_filters}")
    
    # 4. Group By Relevance (15 points)
    expected_group_by = expected.get("group_by")
    actual_group_by = main_value.get("group_by", {}).get("field")
    
    if expected_group_by:
        if actual_group_by == expected_group_by:
            analysis["semantic_score"] += 15
            analysis["matches"].append(f"‚úÖ Correct grouping: {actual_group_by}")
        else:
            analysis["mismatches"].append(f"‚ùå Grouping mismatch: expected {expected_group_by}, got {actual_group_by}")
    elif not actual_group_by:
        analysis["semantic_score"] += 15
        analysis["matches"].append("‚úÖ No grouping needed and none applied")
    else:
        analysis["warnings"].append(f"‚ö†Ô∏è Unexpected grouping: {actual_group_by}")
    
    # 5. Field Relevance for avg operations (10 points)
    expected_field = expected.get("field")
    actual_field = main_value.get("field")
    
    if expected_operation == "avg":
        if expected_field and actual_field == expected_field:
            analysis["semantic_score"] += 10
            analysis["matches"].append(f"‚úÖ Correct avg field: {actual_field}")
        elif expected_field and actual_field != expected_field:
            analysis["mismatches"].append(f"‚ùå Avg field mismatch: expected {expected_field}, got {actual_field}")
        elif not expected_field and actual_field:
            analysis["semantic_score"] += 8  # Points for including a field even if not specifically expected
            analysis["matches"].append(f"‚úÖ Included avg field: {actual_field}")
    elif actual_operation == "avg" and not actual_field:
        analysis["mismatches"].append("‚ùå avg operation missing required field parameter")
    else:
        analysis["semantic_score"] += 10  # Full points for non-avg operations
    
    # 6. Title Relevance (20 points)
    expected_keywords = expected.get("title_keywords", [])
    title_lower = title.lower()
    
    keyword_matches = 0
    for keyword in expected_keywords:
        if keyword.lower() in title_lower:
            keyword_matches += 1
    
    if keyword_matches > 0:
        title_score = min(20, (keyword_matches / len(expected_keywords)) * 20)
        analysis["semantic_score"] += title_score
        analysis["matches"].append(f"‚úÖ Title relevance: {keyword_matches}/{len(expected_keywords)} keywords matched")
    else:
        analysis["mismatches"].append("‚ùå Title doesn't contain expected keywords")
    
    # Determine semantic quality
    if analysis["semantic_score"] >= 85:
        quality = "EXCELLENT"
        quality_emoji = "üåü"
    elif analysis["semantic_score"] >= 70:
        quality = "GOOD"
        quality_emoji = "‚úÖ"
    elif analysis["semantic_score"] >= 50:
        quality = "FAIR"
        quality_emoji = "‚ö†Ô∏è"
    else:
        quality = "POOR"
        quality_emoji = "‚ùå"
    
    analysis["quality"] = quality
    analysis["quality_emoji"] = quality_emoji
    
    # Store detailed analysis
    analysis["detailed_analysis"] = {
        "title": title,
        "actual_entity": actual_entity,
        "actual_operation": actual_operation,
        "actual_filter": actual_filter,
        "actual_group_by": actual_group_by,
        "actual_field": actual_field,
        "expected": expected
    }
    
    return analysis

async def send_chat_request(query: str) -> str:
    """Send chat request to get response"""
    url = "http://localhost:8001/chat"
    
    payload = {
        "message": query,
        "model": "deepseek",
        "use_real_data": False,
        "temperature": 0.1
    }
    
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(url, json=payload)
            response.raise_for_status()
            
            result = response.json()
            return result.get("response", "No response received")
            
    except Exception as e:
        return f"ERROR: {str(e)}"

async def run_semantic_validation():
    """Run semantic validation on test cases"""
    print("üß† Starting Semantic Relevance Validation")
    print("=" * 80)
    
    results = []
    total_semantic_score = 0
    valid_responses = 0
    
    for test_case in SEMANTIC_TEST_CASES:
        semantic_focus = test_case['expected_elements']['semantic_focus'].replace('_', ' ').title()
        print(f"\nüìã Test {test_case['id']}: {semantic_focus}")
        print(f"Query: {test_case['query']}")
        print("-" * 60)
        
        # Get response
        response = await send_chat_request(test_case['query'])
        
        if response.startswith("ERROR:"):
            print(f"‚ùå Request failed: {response}")
            continue
        
        try:
            # Parse JSON response
            if '```json' in response:
                start = response.find('```json') + 7
                end = response.find('```', start)
                if end != -1:
                    json_content = response[start:end].strip()
            else:
                json_content = response
                
            response_json = json.loads(json_content)
            
            # Analyze semantic relevance
            analysis = analyze_semantic_relevance(
                test_case['query'], 
                response_json, 
                test_case['expected_elements']
            )
            
            # Display results
            print(f"{analysis['quality_emoji']} {analysis['quality']} (Semantic Score: {analysis['semantic_score']}/100)")
            print(f"   üìä Title: {analysis['detailed_analysis']['title']}")
            print(f"   üéØ Focus: {test_case['expected_elements']['semantic_focus'].replace('_', ' ').title()}")
            
            # Show matches
            for match in analysis['matches'][:3]:  # Show first 3 matches
                print(f"   {match}")
            
            # Show mismatches
            for mismatch in analysis['mismatches'][:2]:  # Show first 2 mismatches
                print(f"   {mismatch}")
                
            results.append(analysis)
            total_semantic_score += analysis['semantic_score']
            valid_responses += 1
            
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parsing failed: {str(e)}")
        except Exception as e:
            print(f"‚ùå Analysis failed: {str(e)}")
        
        await asyncio.sleep(0.5)  # Small delay
    
    # Summary analysis
    print("\n" + "=" * 80)
    print("üß† SEMANTIC RELEVANCE ANALYSIS")
    print("=" * 80)
    
    if valid_responses > 0:
        avg_semantic_score = total_semantic_score / valid_responses
        
        # Quality distribution
        excellent = sum(1 for r in results if r['quality'] == 'EXCELLENT')
        good = sum(1 for r in results if r['quality'] == 'GOOD') 
        fair = sum(1 for r in results if r['quality'] == 'FAIR')
        poor = sum(1 for r in results if r['quality'] == 'POOR')
        
        print(f"üåü EXCELLENT: {excellent}/{valid_responses} ({excellent/valid_responses*100:.1f}%)")
        print(f"‚úÖ GOOD: {good}/{valid_responses} ({good/valid_responses*100:.1f}%)")
        print(f"‚ö†Ô∏è FAIR: {fair}/{valid_responses} ({fair/valid_responses*100:.1f}%)")
        print(f"‚ùå POOR: {poor}/{valid_responses} ({poor/valid_responses*100:.1f}%)")
        
        print(f"\nüìä Average Semantic Relevance Score: {avg_semantic_score:.1f}/100")
        
        # Semantic quality assessment
        if avg_semantic_score >= 85:
            assessment = "üåü OUTSTANDING - Perfect semantic understanding"
        elif avg_semantic_score >= 75:
            assessment = "üéØ EXCELLENT - Strong semantic accuracy"
        elif avg_semantic_score >= 65:
            assessment = "‚úÖ GOOD - Generally accurate responses"
        elif avg_semantic_score >= 50:
            assessment = "‚ö†Ô∏è FAIR - Some semantic issues"
        else:
            assessment = "‚ùå POOR - Significant semantic problems"
        
        print(f"\nüéØ Semantic Assessment: {assessment}")
        
        # Common issue analysis
        all_mismatches = []
        for r in results:
            all_mismatches.extend(r['mismatches'])
        
        if all_mismatches:
            print(f"\n‚ö†Ô∏è Most Common Issues:")
            issue_counts = {}
            for issue in all_mismatches:
                # Extract issue type
                if "Entity mismatch" in issue:
                    issue_type = "Entity Selection"
                elif "Operation mismatch" in issue:
                    issue_type = "Operation Selection"  
                elif "Filter" in issue:
                    issue_type = "Filter Logic"
                elif "Grouping" in issue:
                    issue_type = "Grouping Logic"
                else:
                    issue_type = "Other"
                    
                issue_counts[issue_type] = issue_counts.get(issue_type, 0) + 1
            
            for issue_type, count in sorted(issue_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"   ‚Ä¢ {issue_type}: {count} instances")
        else:
            print(f"\nüéâ No semantic issues found!")
    
    return results

if __name__ == "__main__":
    print(f"üïê Semantic validation started at: {datetime.now().isoformat()}")
    results = asyncio.run(run_semantic_validation())
    print(f"üïê Semantic validation completed at: {datetime.now().isoformat()}")