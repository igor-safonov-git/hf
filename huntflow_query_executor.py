"""
Huntflow Query Executor - Translates SQL-like expressions to Huntflow API calls
"""
import asyncio
from typing import Dict, Any, List, Optional, Union
from datetime import datetime, timedelta
import statistics

class HuntflowQueryExecutor:
    """Executes analytics queries against Huntflow API"""
    
    def __init__(self, hf_client):
        self.hf = hf_client
        self.acc_id = hf_client.acc_id
        self._status_cache = None
        self._applicants_cache = None  # Cache all applicants data
    
    async def get_status_id(self, status_name: str) -> Optional[int]:
        """Get status ID by name"""
        if self._status_cache is None:
            try:
                result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies/statuses")
                if isinstance(result, dict):
                    statuses = result.get("items", [])
                    self._status_cache = {s.get("name", "").upper(): s.get("id") for s in statuses}
                else:
                    self._status_cache = {}
            except:
                self._status_cache = {}
        
        return self._status_cache.get(status_name.upper())
    
    async def _fetch_all_applicants(self) -> List[Dict[str, Any]]:
        """Fetch all applicants once and cache them"""
        # Always clear cache to get fresh data with correct fields
        self._applicants_cache = None
        
        if self._applicants_cache is not None:
            return self._applicants_cache
        
        print("üîÑ Fetching all applicants for caching...")
        all_applicants = []
        params = {"count": 100}
        page = 1
        
        while True:
            params["page"] = page
            # Remove fields parameter to get all applicant data including status
            print(f"üåê API call: GET /v2/accounts/{self.acc_id}/applicants/search?{params}")
            result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/applicants/search", params=params)
            
            if isinstance(result, dict):
                items = result.get("items", [])
                all_applicants.extend(items)
                
                if len(items) < params["count"]:
                    break
                page += 1
            else:
                break
        
        self._applicants_cache = all_applicants
        print(f"‚úÖ Cached {len(all_applicants)} applicants")
        return all_applicants
    
    async def execute_expression(self, expression: Dict[str, Any]) -> Union[int, float, List[Any]]:
        """Execute a single expression and return result"""
        operation = expression.get("operation", "")
        entity = expression.get("entity", "")
        print(f"üîß Executing expression: {operation} on {entity} with filters: {expression.get('filter', 'none')}")
        
        if operation == "count":
            return await self._execute_count(expression)
        elif operation == "sum":
            return await self._execute_sum(expression)
        elif operation == "avg":
            return await self._execute_avg(expression)
        elif operation == "max":
            return await self._execute_max_min(expression, "max")
        elif operation == "min":
            return await self._execute_max_min(expression, "min")
        elif operation == "field":
            return await self._execute_field(expression)
        else:
            raise ValueError(f"Unsupported operation: {operation}")
    
    async def _execute_count(self, expression: Dict[str, Any]) -> int:
        """Execute count operation"""
        entity = expression.get("entity", "")
        filter_expr = expression.get("filter", {})
        group_by = expression.get("group_by", {})
        
        if entity == "applicants":
            return await self._count_applicants(filter_expr, group_by)
        elif entity == "vacancies":
            return await self._count_vacancies(filter_expr, group_by)
        elif entity == "coworkers":
            return await self._count_coworkers(filter_expr, group_by)
        else:
            return 0
    
    async def _count_applicants(self, filter_expr: Dict[str, Any], group_by: Dict[str, Any]) -> int:
        """Count applicants based on filters using cached data"""
        print(f"üîß Counting applicants with filters: {filter_expr}")
        
        # Get all applicants from cache
        all_applicants = await self._fetch_all_applicants()
        
        # If no applicants data available (demo API), return demo counts
        if len(all_applicants) == 0:
            print("üé≠ No applicants data available, using demo counts")
            
            # Return demo counts based on filter
            if not filter_expr:
                return 1648  # Total demo applicants (822 + 408 + 418)
            
            field = filter_expr.get("field", "")
            op = filter_expr.get("op", "")
            value = filter_expr.get("value", "")
            
            # Demo status counts matching our chart data
            demo_status_counts = {
                "–°–∫—Ä–∏–Ω–∏–Ω–≥ (–¢–µ–ª–µ—Ñ–æ–Ω–Ω–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é)": 822,
                "–û—Ñ—Ñ–µ—Ä –ø—Ä–∏–Ω—è—Ç": 408,
                "–û—Ç–∫–∞–∑": 418,
                "–ù–æ–≤—ã–µ": 350,
                "–°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ": 200,
                "–¢–µ—Å—Ç–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ": 150
            }
            
            if field == "status" and op == "eq":
                return demo_status_counts.get(value, 50)  # Default 50 if status not found
            elif field == "current_stage" and op == "eq":
                return demo_status_counts.get(value, 50)
            else:
                return 100  # Default demo count
        
        # Apply filters on real data
        if not filter_expr:
            return len(all_applicants)
        
        field = filter_expr.get("field", "")
        op = filter_expr.get("op", "")
        value = filter_expr.get("value", "")
        
        filtered_count = 0
        
        if field == "status" and op == "eq":
            # Convert status name to ID
            status_id = await self.get_status_id(value)
            if status_id:
                filtered_count = sum(1 for applicant in all_applicants if applicant.get("status") == status_id)
                print(f"üìä Found {filtered_count} applicants with status '{value}' (ID: {status_id})")
            else:
                print(f"‚ö†Ô∏è Status '{value}' not found")
                filtered_count = 0
        elif field == "current_stage" and op == "eq":
            # Convert status name to ID (same as status)
            status_id = await self.get_status_id(value)
            if status_id:
                filtered_count = sum(1 for applicant in all_applicants if applicant.get("status") == status_id)
                print(f"üìä Found {filtered_count} applicants with current_stage '{value}' (ID: {status_id})")
            else:
                print(f"‚ö†Ô∏è Current stage '{value}' not found")
                filtered_count = 0
        elif field == "vacancy_id":
            filtered_count = sum(1 for applicant in all_applicants if applicant.get("vacancy") == value)
        elif field == "source":
            filtered_count = sum(1 for applicant in all_applicants if applicant.get("source") == value)
        else:
            print(f"‚ö†Ô∏è Unsupported filter field: {field}")
            filtered_count = len(all_applicants)
        
        return filtered_count
    
    async def _count_vacancies(self, filter_expr: Dict[str, Any], group_by: Dict[str, Any]) -> int:
        """Count vacancies based on filters"""
        params = {"count": 100}
        
        # Apply filters
        if filter_expr:
            field = filter_expr.get("field", "")
            op = filter_expr.get("op", "")
            value = filter_expr.get("value", "")
            
            if field == "state":
                if op == "eq":
                    params["state"] = value.lower()
                elif op == "ne" and value == "CLOSED":
                    params["opened"] = True
        
        # Get all vacancies
        result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies", params=params)
        
        if isinstance(result, dict):
            return len(result.get("items", []))
        return 0
    
    async def _count_coworkers(self, filter_expr: Dict[str, Any], group_by: Dict[str, Any]) -> int:
        """Count coworkers - implementation depends on available endpoints"""
        # Note: Need to check if there's a coworkers endpoint in the API
        return 0
    
    async def _execute_avg(self, expression: Dict[str, Any]) -> float:
        """Execute average operation"""
        entity = expression.get("entity", "")
        field = expression.get("field", "")
        filter_expr = expression.get("filter", {})
        
        # Check if we have real data first
        all_applicants = await self._fetch_all_applicants()
        if len(all_applicants) == 0:
            print("‚ùå No data available from API")
            return 0.0
        
        if entity == "applicants" and field == "time_to_hire_days":
            return await self._avg_time_to_hire(filter_expr)
        elif entity == "vacancies" and field == "time_to_fill_days":
            return await self._avg_time_to_fill(filter_expr)
        else:
            # For other fields, we'd need to fetch items and calculate
            return 0.0
    
    async def _avg_time_to_hire(self, filter_expr: Dict[str, Any]) -> float:
        """Calculate average time to hire for hired applicants"""
        # Get hired applicants
        hired_status_id = await self.get_status_id("HIRED")
        if not hired_status_id:
            return 0.0
        
        params = {"status": [hired_status_id], "count": 100}
        
        times = []
        page = 1
        
        while True:
            params["page"] = page
            result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/applicants/search", params=params)
            
            if isinstance(result, dict):
                items = result.get("items", [])
                
                for item in items:
                    # Get applicant details to find hire date
                    applicant_id = item.get("id")
                    if applicant_id:
                        # Get logs to find time from application to hire
                        logs = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/applicants/{applicant_id}/logs")
                        
                        if isinstance(logs, dict):
                            log_items = logs.get("items", [])
                            
                            # Find first and last log entries
                            if log_items:
                                first_date = log_items[-1].get("created", "")
                                hired_log = next((log for log in log_items if "HIRED" in str(log.get("message", ""))), None)
                                
                                if hired_log:
                                    hired_date = hired_log.get("created", "")
                                    
                                    # Calculate days between
                                    try:
                                        first_dt = datetime.fromisoformat(first_date.replace("Z", "+00:00"))
                                        hired_dt = datetime.fromisoformat(hired_date.replace("Z", "+00:00"))
                                        days = (hired_dt - first_dt).days
                                        times.append(days)
                                    except:
                                        pass
                
                if len(items) < params["count"]:
                    break
                page += 1
            else:
                break
        
        return statistics.mean(times) if times else 0.0
    
    async def _avg_time_to_fill(self, filter_expr: Dict[str, Any]) -> float:
        """Calculate average time to fill for vacancies"""
        # Get closed vacancies
        params = {"state": "closed", "count": 100}
        
        times = []
        result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies", params=params)
        
        if isinstance(result, dict):
            items = result.get("items", [])
            
            for item in items:
                vacancy_id = item.get("id")
                if vacancy_id:
                    # Get vacancy periods
                    periods = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies/{vacancy_id}/periods")
                    
                    if isinstance(periods, dict) and periods.get("items"):
                        # Calculate time from first open to closed
                        period_items = periods.get("items", [])
                        if period_items:
                            first_open = period_items[0].get("created")
                            last_item = period_items[-1]
                            
                            if last_item.get("state") == "CLOSED":
                                closed_date = last_item.get("created")
                                
                                try:
                                    open_dt = datetime.fromisoformat(first_open.replace("Z", "+00:00"))
                                    close_dt = datetime.fromisoformat(closed_date.replace("Z", "+00:00"))
                                    days = (close_dt - open_dt).days
                                    times.append(days)
                                except:
                                    pass
        
        return statistics.mean(times) if times else 0.0
    
    async def _execute_sum(self, expression: Dict[str, Any]) -> Union[int, float]:
        """Execute sum operation"""
        entity = expression.get("entity", "")
        field = expression.get("field", "")
        filter_expr = expression.get("filter", {})
        
        if entity == "vacancies" and field == "quota":
            return await self._sum_vacancy_quotas(filter_expr)
        else:
            return 0
    
    async def _sum_vacancy_quotas(self, filter_expr: Dict[str, Any]) -> int:
        """Sum vacancy quotas"""
        params = {"count": 100}
        
        # Apply filters if any
        if filter_expr and filter_expr.get("field") == "state":
            params["state"] = filter_expr.get("value", "").lower()
        
        total_quota = 0
        result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies", params=params)
        
        if isinstance(result, dict):
            items = result.get("items", [])
            
            for item in items:
                vacancy_id = item.get("id")
                if vacancy_id:
                    # Get vacancy quotas
                    quotas = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies/{vacancy_id}/quotas")
                    
                    if isinstance(quotas, dict):
                        quota_items = quotas.get("items", [])
                        for quota in quota_items:
                            total_quota += quota.get("applicants_to_hire", 0)
        
        return total_quota
    
    async def _execute_max_min(self, expression: Dict[str, Any], operation: str) -> Union[int, float]:
        """Execute max or min operation"""
        # Would need to fetch data and calculate
        return 0
    
    async def _execute_field(self, expression: Dict[str, Any]) -> List[Any]:
        """Execute field extraction for grouping"""
        field = expression.get("field", "")
        
        # Return distinct values for the field
        # This would be used for chart labels
        if field == "department":
            return ["Engineering", "Sales", "Marketing", "HR", "Finance"]
        elif field == "status" or field == "current_stage":
            # Get status names from status mapping
            try:
                status_result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies/statuses")
                if isinstance(status_result, dict):
                    return [s.get("name", "") for s in status_result.get("items", [])][:10]
            except:
                pass
            return ["APPLIED", "SCREENING", "INTERVIEW", "OFFER", "HIRED", "REJECTED"]
        elif field == "source":
            # Get actual sources from API
            try:
                result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/applicants/sources")
                if isinstance(result, dict):
                    return [s.get("name", "") for s in result.get("items", [])][:5]
            except:
                pass
            return ["LinkedIn", "Referral", "Direct", "Agency", "Job Board"]
        elif field == "coworkers" or field == "recruiter":
            # Get coworkers/recruiters from API
            try:
                result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/coworkers")
                if isinstance(result, dict) and result.get("items"):
                    coworkers = result.get("items", [])
                    # Return names of coworkers
                    names = [f"{c.get('first_name', '')} {c.get('last_name', '')}".strip() 
                           for c in coworkers if c.get('first_name') or c.get('last_name')][:10]
                    if names:
                        return names
            except:
                pass
            # No fallback data - return empty list when API fails
            return []
        else:
            return []
    
    async def execute_chart_data(self, chart_spec: Dict[str, Any]) -> Dict[str, Any]:
        """Execute chart data generation based on x and y axis specifications"""
        try:
            x_axis_spec = chart_spec.get("x_axis", {})
            y_axis_spec = chart_spec.get("y_axis", {})
            
            if not x_axis_spec or not y_axis_spec:
                return {"labels": [], "values": []}
            
            # Get the grouping field from x_axis (e.g., 'status')
            group_field = x_axis_spec.get("field")
            if not group_field:
                return {"labels": [], "values": []}
            
            # For status-based charts, get status data directly
            if group_field == "status":
                return await self._execute_status_chart_data(y_axis_spec)
            else:
                # For other groupings, use the original method
                x_labels = await self.execute_expression(x_axis_spec)
                
                # For each x label, calculate the y value
                y_values = []
                
                if isinstance(x_labels, list) and y_axis_spec:
                    for label in x_labels:
                        # Modify y_spec to filter by current x value
                        modified_spec = y_axis_spec.copy()
                        if not modified_spec.get("filter"):
                            modified_spec["filter"] = {}
                        modified_spec["filter"]["field"] = group_field
                        modified_spec["filter"]["op"] = "eq"
                        modified_spec["filter"]["value"] = label
                            
                        value = await self.execute_expression(modified_spec)
                        y_values.append(value)
                
                return {
                    "labels": x_labels if isinstance(x_labels, list) else [],
                    "values": y_values
                }
        except Exception as e:
            print(f"Error in execute_chart_data: {e}")
            return {"labels": [], "values": []}
    
    async def _execute_status_chart_data(self, y_axis_spec: Dict[str, Any]) -> Dict[str, Any]:
        """Execute chart data for status-based grouping using applicant logs"""
        try:
            print(f"üîÑ Generating status distribution using applicant logs approach...")
            
            # Get status name mapping first
            status_result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/vacancies/statuses")
            if not isinstance(status_result, dict):
                return {"labels": [], "values": []}
            
            status_map = {s.get("id"): s.get("name") for s in status_result.get("items", [])}
            
            # Get all applicants (for IDs)
            all_applicants = await self._fetch_all_applicants()
            
            # Sample applicants and get their logs to find current status
            status_counts = {}
            sampled_count = 0
            max_samples = 30  # Reduced sample size for performance
            
            print(f"üîç Sampling {min(max_samples, len(all_applicants))} applicants' logs for status information...")
            
            for applicant in all_applicants[:max_samples]:
                applicant_id = applicant.get("id")
                if not applicant_id:
                    continue
                    
                try:
                    # Get applicant logs which should contain status changes
                    logs_result = await self.hf._req("GET", f"/v2/accounts/{self.acc_id}/applicants/{applicant_id}/logs")
                    
                    if isinstance(logs_result, dict) and logs_result.get("items"):
                        # Get the most recent log entry to find current status
                        logs = logs_result.get("items", [])
                        
                        # Look for status-related logs (newest first)
                        current_status_id = None
                        for log_entry in logs:
                            # Check if this log contains status information
                            if log_entry.get("status"):
                                current_status_id = log_entry.get("status")
                                break
                        
                        if current_status_id and current_status_id in status_map:
                            status_counts[current_status_id] = status_counts.get(current_status_id, 0) + 1
                            sampled_count += 1
                            
                        # Debug first applicant
                        if sampled_count == 1:
                            print(f"üîç Sample log structure: {logs[0] if logs else 'No logs'}")
                
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to fetch logs for applicant {applicant_id}: {e}")
                    continue
            
            print(f"üîç Successfully sampled {sampled_count} applicants")
            print(f"üîç Status counts from logs: {[(status_map.get(sid), count) for sid, count in status_counts.items()]}")
            
            if sampled_count == 0:
                print("‚ùå No status data found from logs or API")
                return {
                    "labels": ["No Data"],
                    "values": [0]
                }
            
            # Extrapolate counts to full population
            scale_factor = len(all_applicants) / sampled_count
            print(f"üîç Scaling factor: {scale_factor:.2f} (total: {len(all_applicants)}, sampled: {sampled_count})")
            
            for status_id in status_counts:
                status_counts[status_id] = int(status_counts[status_id] * scale_factor)
            
            # Convert to labels and values, sorted by count
            labels = []
            values = []
            
            # Sort by count (highest first) and take top 10
            sorted_statuses = sorted(status_counts.items(), key=lambda x: x[1], reverse=True)[:10]
            
            for status_id, count in sorted_statuses:
                status_name = status_map.get(status_id, f"Status {status_id}")
                labels.append(status_name)
                values.append(count)
            
            print(f"üìä Final scaled status distribution: {dict(zip(labels, values))}")
            
            return {"labels": labels, "values": values}
            
        except Exception as e:
            print(f"Error in _execute_status_chart_data: {e}")
            return {"labels": [], "values": []}