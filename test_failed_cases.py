"""
Test the specific failed cases from previous metric accuracy test
Focus on the 7 cases that failed to see if comprehensive prompt fixes them
"""

import asyncio
import json
import aiohttp

async def test_failed_cases():
    """Test the specific cases that failed in previous test"""
    
    failed_cases = [
        {
            "question": "ÐžÑ‚ÐºÑƒÐ´Ð° Ð¿Ñ€Ð¸Ñ…Ð¾Ð´ÑÑ‚ Ð½Ð°ÑˆÐ¸ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ñ‹?",
            "expected_entity": "applicants_by_source",
            "expected_operation": "count"
        },
        {
            "question": "ÐšÐ°ÐºÐ°Ñ ÐºÐ¾Ð½Ð²ÐµÑ€ÑÐ¸Ñ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¹ Ð² Ð½Ð°Ð¹Ð¼?",
            "expected_entity": "vacancy_conversion_summary", 
            "expected_operation": "avg"
        },
        {
            "question": "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ñ‹ Ð¿Ñ€Ð¾Ð²Ð¾Ð´ÑÑ‚ Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÑÑ‚Ð°Ñ‚ÑƒÑÐµ?",
            "expected_entity": "time_in_status",
            "expected_operation": "avg"
        },
        {
            "question": "ÐšÐ°Ðº Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»Ð°ÑÑŒ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ð¼ÐµÑÑÑ†Ñ‹?",
            "expected_entity": "applicant_activity_trends",
            "expected_operation": "count"
        },
        {
            "question": "ÐšÐ°ÐºÐ¸Ðµ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹ Ð¾Ñ‚ÐºÐ°Ð·Ð¾Ð² ÑÐ°Ð¼Ñ‹Ðµ Ñ‡Ð°ÑÑ‚Ñ‹Ðµ?",
            "expected_entity": "rejections_by_stage",
            "expected_operation": "sum"
        },
        {
            "question": "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¹ Ð¼Ñ‹ Ð·Ð°ÐºÑ€Ñ‹Ð»Ð¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾?",
            "expected_entity": "successful_closures",
            "expected_operation": "count"
        },
        {
            "question": "ÐšÐ°ÐºÐ°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñƒ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ñ€ÐµÐºÑ€ÑƒÑ‚ÐµÑ€Ð°?",
            "expected_entity": "applicants_by_recruiter",
            "expected_operation": "avg"
        }
    ]
    
    print("ðŸŽ¯ Testing Previously Failed Cases with Comprehensive Prompt")
    print("=" * 60)
    
    improvements = 0
    total_tests = len(failed_cases)
    
    async with aiohttp.ClientSession() as session:
        for i, test in enumerate(failed_cases, 1):
            print(f"\nðŸ“Š Test {i}/{total_tests}: {test['question']}")
            print("-" * 40)
            
            payload = {"message": test["question"], "use_local_cache": True}
            
            try:
                async with session.post("http://localhost:8001/chat", json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        if "response" in result:
                            parsed = json.loads(result["response"])
                            
                            # Extract actual metric
                            actual_entity = parsed.get("main_metric", {}).get("value", {}).get("entity", "")
                            actual_operation = parsed.get("main_metric", {}).get("value", {}).get("operation", "")
                            
                            # Compare
                            entity_match = test["expected_entity"] == actual_entity
                            operation_match = test["expected_operation"] == actual_operation
                            
                            print(f"Expected: {test['expected_entity']}.{test['expected_operation']}")
                            print(f"Actual:   {actual_entity}.{actual_operation}")
                            print(f"Entity: {'âœ…' if entity_match else 'âŒ'}")
                            print(f"Operation: {'âœ…' if operation_match else 'âŒ'}")
                            
                            if entity_match and operation_match:
                                print("ðŸŽ‰ FIXED! Perfect match!")
                                improvements += 1
                            elif entity_match:
                                print("âš¡ Entity FIXED! Operation still needs work")
                            elif operation_match:
                                print("âš¡ Operation FIXED! Entity still needs work")
                            else:
                                print("âŒ Still failing")
                        
                    else:
                        print(f"âŒ HTTP Error: {response.status}")
                        
            except Exception as e:
                print(f"âŒ Error: {e}")
    
    print(f"\nðŸ“ˆ IMPROVEMENT SUMMARY")
    print("=" * 30)
    print(f"Previously failed cases: {total_tests}")
    print(f"Now working perfectly: {improvements}")
    print(f"Improvement rate: {improvements/total_tests:.1%}")
    
    if improvements > 0:
        print(f"ðŸŽ‰ Comprehensive prompt fixed {improvements} cases!")
    else:
        print("ðŸ˜• No improvements detected - prompt needs more work")

if __name__ == "__main__":
    asyncio.run(test_failed_cases())